{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6659552e",
   "metadata": {},
   "source": [
    "# Custom text classification using OCI Language Service Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c23a78",
   "metadata": {},
   "source": [
    "This Notebook demonstrates how to call batch text classification API to classify text using custom text classification model from OCI Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59e6709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import oci\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from typing import Any, Dict, List, Union\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15d8fa",
   "metadata": {},
   "source": [
    "## Initialize OCI AI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f465fc5",
   "metadata": {},
   "source": [
    "Make sure you have setup config file by following steps mentioned in </br>\n",
    "[OCI Langauge Service Live lab Task-1](https://apexapps.oracle.com/pls/apex/dbpm/r/livelabs/run-workshop?p210_wid=887&p210_wec=&session=108183149172107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516bc108",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_client = oci.ai_language.AIServiceLanguageClient(oci.config.from_file(profile_name='AISERVICESPM'))\n",
    "ai_client.base_client.timeout = 30\n",
    "wait_between_batch = 0\n",
    "wait_between_retries = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713e40e",
   "metadata": {},
   "source": [
    "Read the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe163467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/Downloads/35_rep_data_feb_1.csv', nrows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956f64a",
   "metadata": {},
   "source": [
    "### split the dataset into batches\n",
    "OCI endpoint can process upto 500 characters per second. OCI Language batch API has a limit of max 100 documents and 20k characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2118f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rec_for_batch_call = 100\n",
    "max_tex_per_batch = 18000\n",
    "model_endpoint = 'ocid1.ailanguageendpoint.oc1.phx.amaaaaaa3nkmftyafnulvuggyditrznsudni26b2csubumikicbunfmz6h6a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603b7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_upadate_batch(df):\n",
    "    output = None\n",
    "    documents = [oci.ai_language.models.TextDocument(key=str(p), text=row['text']) for p,row in df.iterrows()]\n",
    "    prediction = [None] * len(documents)\n",
    "    confidence = [None] * len(documents)\n",
    "    \n",
    "    classificaton_details = oci.ai_language.models.BatchDetectLanguageTextClassificationDetails(endpoint_id=model_endpoint,documents = documents)\n",
    "    retry_count = 0\n",
    "    success=False\n",
    "    \n",
    "    start_index = df.index.min()\n",
    "    \n",
    "    MAX_RETRYCOUNT=3\n",
    "    while retry_count <MAX_RETRYCOUNT and success != True:\n",
    "        try:\n",
    "            start_time = datetime.datetime.now()\n",
    "            output = ai_client.batch_detect_language_text_classification(classificaton_details)\n",
    "            end_time = datetime.datetime.now()\n",
    "            print(f'{datetime.datetime.now()} processing of {len(documents)} records, total chars: {df.text.str.len().sum()} took :{end_time-start_time}')\n",
    "            \n",
    "            index = [int(d.key) for d in output.data.documents ]\n",
    "            predicted_labels = ['|'.join([c.label for c in d.text_classification])  for d in output.data.documents ]\n",
    "            #predicted_labels = [d.text_classification[0].label if len(d.text_classification) >0 else None for d in output.data.documents]\n",
    "            predicted_conf = ['|'.join([str(c.score) for c in d.text_classification])  for d in output.data.documents ]\n",
    "            errors = [e.key for e in output.data.errors]\n",
    "            success = True\n",
    "            \n",
    "            if len(df) != len(predicted_labels):\n",
    "                print(f'{datetime.datetime.now()} failed inference for {len(df)-len(predicted_labels)} records')\n",
    "            \n",
    "            #dealing with predictoin errors, predicting a class could fail due to max/min length, wrong encoding ,etc\n",
    "            '''\n",
    "            i = 0\n",
    "            for l in predicted_labels:\n",
    "                if i+start_index in errors:\n",
    "                    print(f'there was an error at {i+start_index}')\n",
    "                    prediction[i] = None\n",
    "                else:\n",
    "                    prediction[i] = predicted_labels[i]\n",
    "                    confidence[i] = predicted_conf [i]\n",
    "                i = i+1\n",
    "            '''\n",
    "            prediction = predicted_labels\n",
    "            confidence = predicted_conf\n",
    "        except oci.exceptions.ServiceError as e:\n",
    "            print(f'{datetime.datetime.now()} Unable to process these records {df.index.min()}: {df.index.max}. Retrying {retry_count} time')\n",
    "            if retry_count == 0: \n",
    "                print(f'Error details:{e}')\n",
    "            time.sleep(wait_between_retries)\n",
    "        except oci.exceptions.ClientError as e:\n",
    "            print(f'{datetime.datetime.now()} Error occurred while processing records {df.index.min()}: {df.index.max()}. Retrying {retry_count} time')\n",
    "            if retry_count == 0: \n",
    "                print(f'Error details:{e}')\n",
    "            time.sleep(wait_between_retries)\n",
    "        except Exception as e:\n",
    "            print(f'{datetime.datetime.now()} Error occurred while processing records {df.index.min()}: {df.index.max()}. Retrying {retry_count} time')\n",
    "            if retry_count == 0: \n",
    "                print(f'Error details:{e}')\n",
    "            time.sleep(wait_between_retries)\n",
    "        finally:\n",
    "            retry_count = retry_count +1\n",
    "\n",
    "    return index, prediction, confidence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046d84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_update_slice(df):\n",
    "    for name, group in df.groupby((df.text.str.len().cumsum()/max_tex_per_batch).apply(math.floor)):\n",
    "        row_start = 0\n",
    "        while row_start < group.shape[0]:\n",
    "            rows = group[row_start:row_start+max_rec_for_batch_call]\n",
    "            \n",
    "            print(f'{datetime.datetime.now()} processing rows:{group[row_start:row_start+max_rec_for_batch_call].index.min()}:{group[row_start:row_start+max_rec_for_batch_call].index.max()}')\n",
    "            \n",
    "            index, prediction, confidence = process_and_upadate_batch(rows)\n",
    "\n",
    "            #print(f'sub batch items{row_start}:{row_start+max_rec_for_batch_call} prediction:{len(prediction)}, conf:{len(confidence)}')\n",
    "            df.loc[index,'predicted'] = prediction\n",
    "            df.loc[index,'confidence'] = confidence\n",
    "            \n",
    "            row_start = row_start + max_rec_for_batch_call\n",
    "            time.sleep(wait_between_batch)\n",
    "    print(f'{datetime.datetime.now()} completed processing {len(df)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815adc4",
   "metadata": {},
   "source": [
    "Predicting classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511bfea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 18:29:11.505232 processing rows:0:19\n",
      "2023-03-15 18:29:12.998144 processing of 20 records, total chars: 12593 took :0:00:01.490943\n",
      "2023-03-15 18:29:13.001266 completed processing 20 rows\n"
     ]
    }
   ],
   "source": [
    "df['predicted']=None\n",
    "df['confidence'] = None\n",
    "df['missed'] = None\n",
    "df['extra'] = None\n",
    "process_and_update_slice(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db58cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore failed inferences, could be due to wrong encoding format - TBD investiggate further\n",
    "predicted_df = df.dropna(subset=['predicted', 'confidence']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ed3276",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predicted_df.predicted.str.split('|').apply(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a0c5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = predicted_df.labels.str.split('|').apply(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642573d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df['AllCorrect'] = (y_pred==y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df29f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_preds(row):\n",
    "    preds = []\n",
    "    if row.predicted is not None and len(row.predicted)>0:\n",
    "        preds = row.predicted.split('|')\n",
    "    \n",
    "    labels = row.labels.split('|')\n",
    "    missed = sorted(set(labels).difference(preds))\n",
    "    return missed\n",
    "\n",
    "\n",
    "def extra_preds(row):\n",
    "    preds = []\n",
    "    if row.predicted is not None and len(row.predicted)>0:\n",
    "        preds = row.predicted.split('|')\n",
    "    labels = row.labels.split('|')\n",
    "    extra = sorted(set(preds).difference(labels))\n",
    "    return extra\n",
    "\n",
    "predicted_df['missed'] = predicted_df.apply(missed_preds, axis=1)\n",
    "predicted_df['extra'] = predicted_df.apply(extra_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b3cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb00b4",
   "metadata": {},
   "source": [
    "# Code to prepare class metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155c327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d7a100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "labels = set(itertools.chain(*[i for i in y_pred.values if i is not None and len(i)>0])).union(itertools.chain(*[i for i in y_true.values if i is not None and len(i)>0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b935ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if '' in labels:\n",
    "#    labels.remove('')\n",
    "labels = sorted(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c8125b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "binarizer = MultiLabelBinarizer(classes=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a8d598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_transformed = binarizer.fit_transform(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "492d3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_mask = y_pred.notnull()\n",
    "\n",
    "y_pred_transformed_arr = binarizer.transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40b28ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_transformed = binarizer.transform(y_pred)\n",
    "confusion_matrix = multilabel_confusion_matrix(y_true=y_true_transformed, y_pred=y_pred_transformed)#, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e8f7cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['OPERATIONS'],\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " ['OPERATIONS', 'BAGGAGE HANDLING'],\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[1],y_true_transformed[1], y_pred[1], y_pred_transformed_arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cc78861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FUTURE TRAVEL QUESTIONS'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "labels[np.where(y_pred_transformed[4])[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86156336",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [cm.reshape(-1) for cm in confusion_matrix]\n",
    "class_metrics = pd.DataFrame(columns=['TN','FP','TP', 'FN'], index=labels, data=vals)\n",
    "class_metrics.index.name='class'\n",
    "class_metrics['Precision'] = class_metrics['TP']/(class_metrics.TP+class_metrics.FP)\n",
    "class_metrics['Recall'] = class_metrics['TP']/(class_metrics.TP+class_metrics.FN)\n",
    "class_metrics['F1'] = 2*class_metrics['Precision']*class_metrics['Recall']/(class_metrics['Precision']+class_metrics['Recall'])\n",
    "class_metrics.sort_index().to_csv('~/Downloads/35_rep_data_feb_1_class_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f622e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_metrics.to_csv('classmetrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5193d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('~/Downloads/35_rep_data_feb_1_prediction_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88506f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
